## Data Management Over Distributed APIs

The goal of the project is to manipulate data using popular distributed big data frameworks or APIs. The various implementations allow us to evaluate how different data models affect performance and report and explain the results. <br>

The four APIs we experimented with are:

1.  Hadoop MapReduce
2.  Apache Spark: Sparksâ€™ RDD or the DataFrames API
3.  Apache Flink DataSet API 
4.  Apache Flink Streaming API


**Tools** <br>

* IntelliJ IDEA
* Maven Build tool
* Java 8 
* Gradle build tool
* Docker
* Spark
* Hadoop
* Flink
* Ubuntu
## Datasets
For the project we used three dataset

* DEBS 2013 Grand Challenge dataset
* Customer and the Orders dataset
* Directed graph dataset of a Collaboration Network

## Links to the implementation
1.  [MapReduce Implementation](https://github.com/htefera/Scalable-Data-science-Project-1/tree/master/Mapreduce%20Task)
2. [Spark Batch Processing Implementation](https://github.com/htefera/Scalable-Data-science-Project-1/tree/master/Spark%20Batch%20Processing%20Task)
3. [Flink Dataset API Implementation](https://github.com/htefera/Scalable-Data-science-Project-1/tree/master/Flink%20Dataset%20API%20Task)
4. [Flink Streaming API Implementation](https://github.com/htefera/Scalable-Data-science-Project-1/tree/master/Flink%20Streaming%20API%20Task)

 
